````markdown
# Multiagentes: Sistema de Arquitetura de SoluÃ§Ãµes com CrewAI e Ollama

## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio implementa um sistema **multiagentes** para automaÃ§Ã£o de tarefas tÃ©cnicas usando o framework **CrewAI** e o modelo de linguagem **Phi-3 Mini** via **Ollama**, com execuÃ§Ã£o 100% offline e suporte a **GPU NVIDIA GTX 1050 Ti**.

TrÃªs agentes atuam sequencialmente:
- **Arquiteto de SoluÃ§Ãµes:** Cria o desenho de arquitetura e um ADR.
- **Tech Lead:** Revisa a arquitetura, sugerindo melhorias.
- **Gerente de Tecnologia:** Gera um relatÃ³rio com custo, cronograma e benefÃ­cios.

### âš™ï¸ Funcionalidades
- âœ… ExecuÃ§Ã£o offline com **Ollama + Phi-3 Mini**
- âœ… CoordenaÃ§Ã£o multiagente via **CrewAI**
- âœ… Suporte a **GPU modesta (GTX 1050 Ti, 4GB VRAM)**
- âœ… Logs detalhados com raciocÃ­nio dos agentes
- âœ… Foco em **integraÃ§Ã£o B2B/B2C com EntraID**
- âœ… Estrutura modular para novos agentes/tarefas

---

## ğŸ§  Arquitetura TÃ©cnica

### ğŸ§© Componentes
- **CrewAI:** Framework de agentes coordenados
- **Ollama:** Servidor local compatÃ­vel com API OpenAI
- **Phi-3 Mini:** Modelo quantizado de ~3.8B parÃ¢metros (4-bit)
- **litellm:** Gerencia chamadas ao Ollama local

### ğŸ” Fluxo de Trabalho
```mermaid
graph TD
    A[Arquiteto: Gera Desenho e ADR] --> B[Tech Lead: Revisa Arquitetura]
    B --> C[Gerente: Produz RelatÃ³rio]
````

---

## ğŸ–¥ï¸ Requisitos

### ğŸ”§ Hardware

* GPU: NVIDIA GTX 1050 Ti (4 GB) ou superior
* RAM: 8 GB+
* Armazenamento: 5 GB livres
* SO: Windows 10/11 (testado), Linux/macOS (com ajustes)

### ğŸ“¦ Software

* Python 3.8+
* Ollama (Ãºltima versÃ£o)
* Drivers NVIDIA com CUDA
* CUDA Toolkit 11.8 ou 12.x

```bash
pip install crewai litellm openai requests
```

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Instale o Ollama

```bash
ollama pull phi3-mini
```

### 2. Configure a GPU

* Instale drivers e CUDA Toolkit 11.8+
* (Opcional) ForÃ§ar uso da GPU:

```powershell
$env:CUDA_VISIBLE_DEVICES = "0"
```

### 3. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/multiagentes.git
cd multiagentes
```

### 4. Crie o ambiente virtual

```bash
python -m venv .venv
.\.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/macOS
pip install crewai litellm openai requests
```

---

## â–¶ï¸ Uso

### 1. Inicie o Ollama

```bash
ollama serve
```

### 2. Execute o sistema

```bash
python agentes_arquitetura_offline.py
```

### 3. Monitore a GPU (opcional)

```bash
nvidia-smi
```

**Uso esperado:** \~2-3 GB de VRAM, 50-90% de utilizaÃ§Ã£o

---

## ğŸ“ Exemplo de SaÃ­da

**Arquiteto de SoluÃ§Ãµes**

```text
Desenho: Tenant B2B -> EntraID -> Tenant B2C
ADR:
- Contexto: IntegraÃ§Ã£o segura entre tenants
- DecisÃ£o: Usar EntraID como IdP Ãºnico
- ConsequÃªncias: Simplifica gestÃ£o, exige configuraÃ§Ã£o inicial
```

**Tech Lead**

```text
Adicionado Azure API Management como Gateway
Corrigido para OAuth 2.0 em ambos os tenants
```

**Gerente de Tecnologia**

```text
- Custo: $5.000/mÃªs
- Prazo: 4 meses
- BenefÃ­cios: SeguranÃ§a, escalabilidade, integraÃ§Ã£o simplificada
```

---

## ğŸ§© Extensibilidade

### â• Novos Agentes

```python
especialista_seguranca = Agent(
    role="Especialista em SeguranÃ§a",
    goal="Garantir seguranÃ§a da arquitetura",
    llm="ollama/phi3-mini"
)
```

### ğŸ”„ Outros Modelos

```bash
ollama pull mistral --quantize q4_0
```

---

## âš ï¸ LimitaÃ§Ãµes

* **GPU**: 4 GB de VRAM limita modelos maiores e mÃºltiplas iteraÃ§Ãµes simultÃ¢neas
* **Phi-3 Mini**: Respostas simplificadas para tarefas complexas
* **ConfiguraÃ§Ã£o**: Exige instalaÃ§Ã£o manual de Ollama, drivers e CUDA

---

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas!

```bash
git checkout -b feature/nova-funcionalidade
git commit -m "Adiciona nova funcionalidade"
git push origin feature/nova-funcionalidade
```

SugestÃµes:

* Novos agentes (ex.: Especialista em SeguranÃ§a)
* OtimizaÃ§Ã£o de prompts
* Suporte a novos modelos ou GPUs

---

## ğŸ“„ LicenÃ§a

MIT License â€“ veja o arquivo [LICENSE](LICENSE)

---

## ğŸ“š CitaÃ§Ã£o

```text
Sistema Multiagentes para Arquitetura de SoluÃ§Ãµes  
Autor: [Seu Nome]  
RepositÃ³rio: https://github.com/seu-usuario/multiagentes
```

---

## ğŸ“¬ Contato

**Autor:** \CaduBarbosa
**GitHub:** \CaduBarbosaBR
**X (Twitter):** \CaduBarbosaBR

---

## ğŸ” Notas de SeguranÃ§a

* NÃ£o envie arquivos `.log` para o repositÃ³rio (via `.gitignore`)
* Valide os prompts antes de uso em ambiente corporativo
* O projeto roda 100% offline (sem chamadas externas)

---

## ğŸ“ .gitignore

```
.venv/
__pycache__/
*.log
*.pyc
```

---

## âœ… PublicaÃ§Ã£o no GitHub

1. Crie o repositÃ³rio: `multiagentes`
2. Adicione `README.md`, `LICENSE`, `.gitignore`, e `agentes_arquitetura_offline.py`
3. Inicialize o Git:

```bash
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/seu-usuario/multiagentes.git
git push -u origin main
```

---

## ğŸ“Œ PrÃ³ximos Passos

* Adicione capturas de tela (ex.: `nvidia-smi`, logs)
* Expanda com agentes adicionais
* Exporte saÃ­das para CSV:

```python
import csv
outputs = [{"Agente": task.agent.role, "SaÃ­da": task.execute_sync()} for task in equipe.tasks]
with open('agent_outputs.csv', 'w', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=["Agente", "SaÃ­da"])
    writer.writeheader()
    writer.writerows(outputs)
```

---

Explore o poder dos **sistemas multiagentes offline** com CrewAI + Ollama!

```
